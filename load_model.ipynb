{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2b36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filip\\Documents\\code\\Partial_Additive_Speech\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:unexpected tensor: projection.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: checkpoints/ecapa_tdnn_musan/latest_checkpoint.pth\n",
      "Model loaded successfully from epoch 50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import wespeaker\n",
    "\n",
    "\n",
    "def load_model_from_path(model, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load model from a specific checkpoint path\n",
    "    \n",
    "    Args:\n",
    "        model: The model to load weights into\n",
    "        checkpoint_path: Path to the checkpoint file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Checkpoint information including model state and metadata\n",
    "    \"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading model from: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        checkpoint_info = {\n",
    "            'epoch': checkpoint.get('epoch', 0),\n",
    "            'min_eer': checkpoint.get('min_eer', float('inf')),\n",
    "            'model_state': checkpoint.get('model_state', {})\n",
    "        }\n",
    "        \n",
    "        print(f\"Model loaded successfully from epoch {checkpoint_info['epoch']}\")\n",
    "        return checkpoint_info\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No checkpoint found at {checkpoint_path}\")\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ecapa_tdnn = wespeaker.load_model_local(\"models/voxceleb_ECAPA1024\")\n",
    "model = ecapa_tdnn.model.to(device)\n",
    "model_loaded = load_model_from_path(model, 'checkpoints/ecapa_tdnn_musan/latest_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ec2ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(80, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): SE_Res2Block(\n",
       "    (se_res2block): Sequential(\n",
       "      (0): Conv1dReluBn(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Res2Conv1dReluBn(\n",
       "        (convs): ModuleList(\n",
       "          (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv1dReluBn(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): SE_Connect(\n",
       "        (linear1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): SE_Res2Block(\n",
       "    (se_res2block): Sequential(\n",
       "      (0): Conv1dReluBn(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Res2Conv1dReluBn(\n",
       "        (convs): ModuleList(\n",
       "          (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv1dReluBn(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): SE_Connect(\n",
       "        (linear1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): SE_Res2Block(\n",
       "    (se_res2block): Sequential(\n",
       "      (0): Conv1dReluBn(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Res2Conv1dReluBn(\n",
       "        (convs): ModuleList(\n",
       "          (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv1dReluBn(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): SE_Connect(\n",
       "        (linear1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(3072, 1536, kernel_size=(1,), stride=(1,))\n",
       "  (pool): ASTP(\n",
       "    (linear1): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=3072, out_features=192, bias=True)\n",
       "  (bn2): Identity()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aef869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 6,367,680 / 14,657,088 (43.44%)\n"
     ]
    }
   ],
   "source": [
    "# Freeze lower layers\n",
    "for param in model.layer1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.layer2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Partially unfreeze layer4 - only make SE_Connect trainable\n",
    "for name, param in model.layer4.named_parameters():\n",
    "    if \"se_res2block.3\" in name:  # SE_Connect module\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Ensure upper layers are trainable (they are by default, but being explicit)\n",
    "for param in model.conv.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.pool.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.bn.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.linear.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify which layers are trainable\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\n",
    "    f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params/total_params:.2%})\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
