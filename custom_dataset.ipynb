{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a87fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torchaudio.compliance.kaldi as kaldi\n",
    "import torch\n",
    "import config\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def compute_fbank(\n",
    "    wavform,\n",
    "    sample_rate=16000,\n",
    "    num_mel_bins=80,\n",
    "    frame_length=25,\n",
    "    frame_shift=10,\n",
    "    cmn=True,\n",
    "):\n",
    "    feat = kaldi.fbank(\n",
    "        wavform,\n",
    "        num_mel_bins=num_mel_bins,\n",
    "        frame_length=frame_length,\n",
    "        frame_shift=frame_shift,\n",
    "        sample_frequency=sample_rate,\n",
    "    )\n",
    "    if cmn:\n",
    "        feat = feat - torch.mean(feat, 0)\n",
    "    return feat\n",
    "\n",
    "\n",
    "class CustomNoisyEnrollSet(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for enrollment with a custom directory structure where audio files\n",
    "    are organized by speaker ID directly without video name subdirectories.\n",
    "\n",
    "    The directory structure is expected to be:\n",
    "    root_path/\n",
    "        speaker_id1/\n",
    "            audio1.wav\n",
    "            audio2.wav\n",
    "            ...\n",
    "        speaker_id2/\n",
    "            audio1.wav\n",
    "            ...\n",
    "\n",
    "    `__getitem__(idx)` returns `(utter, spk_id)` where:\n",
    "    `spk_id:str`            - The speaker ID (directory name)\n",
    "    `utter:torch.Tensor`    - Batched utterance features of shape [batch, time, features]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_path,\n",
    "        audio_extension=\".wav\",\n",
    "        sys_config=config.SysConfig(),\n",
    "        exp_config=config.ExpConfig(),\n",
    "    ) -> None:\n",
    "        super(CustomNoisyEnrollSet, self).__init__()\n",
    "        self.path_root_dir = root_path\n",
    "        self.utter_length = exp_config.test_sample\n",
    "        self.audio_extension = audio_extension\n",
    "\n",
    "        # Build speaker-to-audio mapping\n",
    "        self.samples = []\n",
    "        for speaker_id in os.listdir(root_path):\n",
    "            speaker_dir = os.path.join(root_path, speaker_id)\n",
    "            if os.path.isdir(speaker_dir):\n",
    "                for audio_file in os.listdir(speaker_dir):\n",
    "                    if audio_file.endswith(audio_extension):\n",
    "                        self.samples.append(\n",
    "                            {\n",
    "                                \"speaker_id\": speaker_id,\n",
    "                                \"audio_path\": os.path.join(speaker_id, audio_file),\n",
    "                            }\n",
    "                        )\n",
    "        print(f\"Found {len(self.samples)} samples in {root_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        speaker_id = sample[\"speaker_id\"]\n",
    "        audio_path = sample[\"audio_path\"]\n",
    "\n",
    "        # Get utterance\n",
    "        path = os.path.join(self.path_root_dir, audio_path)\n",
    "\n",
    "        # Load only a portion of the audio for quick debugging\n",
    "        # Use a smaller segment for faster loading\n",
    "        utter, sr = torchaudio.load(path, num_frames=self.utter_length)\n",
    "        utter = torch.squeeze(utter)\n",
    "\n",
    "        # Apply fbank directly without batching for now\n",
    "        if utter.dim() == 1:  # If mono\n",
    "            utter = utter.unsqueeze(0)  # Add channel dimension\n",
    "        utter = compute_fbank(utter)\n",
    "\n",
    "        utter = utter.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        return utter, audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41da024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9119 samples in ../SV-eval/data/noisy/gaussian/vox1_test_segments_snr_10_noisy_gaussian/\n",
      "torch.Size([1, 1, 318, 80])\n",
      "('id10270\\\\00001_seg_0.wav',)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "custom_dataset = CustomNoisyEnrollSet(\n",
    "\n",
    "    root_path=\"../SV-eval/data/noisy/gaussian/vox1_test_segments_snr_10_noisy_gaussian/\",  # Path containing speaker id directories\n",
    "\n",
    "    audio_extension=\".wav\",  # Change if your files use a different extension\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Create a DataLoader\n",
    "\n",
    "# Create a smaller subset of the dataset for testing\n",
    "\n",
    "\n",
    "# Create a DataLoader with just a few samples\n",
    "\n",
    "debug_loader = torch.utils.data.DataLoader(\n",
    "\n",
    "    custom_dataset, batch_size=1, shuffle=False, num_workers=0  # Use 0 for debugging\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# show first batch from the debug loader\n",
    "\n",
    "for batch in debug_loader:\n",
    "\n",
    "    print(batch[0].shape)  # utterance tensor\n",
    "\n",
    "    print(batch[1])  # speaker ID\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32188ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (37611, 3)\n",
      "\n",
      "First few rows:\n",
      "   label                         audio1                         audio2\n",
      "0      1  id10270/x6uYqmx31kE/00001.wav  id10270/8jEAjG6SegY/00008.wav\n",
      "1      0  id10270/x6uYqmx31kE/00001.wav  id10300/ize_eiCFEg0/00003.wav\n",
      "2      1  id10270/x6uYqmx31kE/00001.wav  id10270/GWXujl-xAVM/00017.wav\n",
      "3      0  id10270/x6uYqmx31kE/00001.wav  id10273/0OCW1HUxZyg/00001.wav\n",
      "4      1  id10270/x6uYqmx31kE/00001.wav  id10270/8jEAjG6SegY/00022.wav\n",
      "\n",
      "Distribution of same/different pairs:\n",
      "label\n",
      "0    18809\n",
      "1    18802\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_16788\\3668648507.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\"label/vox1_test.csv\", delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"label/vox1_test.csv\", delim_whitespace=True)\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "print(\"Shape of dataframe:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic statistics about the 'same' column (1 for same speaker, 0 for different)\n",
    "print(\"\\nDistribution of same/different pairs:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31a926e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 speakers\n",
      "Created trial list with 16000 positive and 16000 negative pairs\n",
      "Total trials: 32000\n",
      "Saved to label/gaussian_trials.csv\n",
      "\n",
      "Verifying trial list from label/gaussian_trials.csv\n",
      "Shape of dataframe: (32000, 3)\n",
      "\n",
      "First few rows:\n",
      "   label                    audio1                   audio2\n",
      "0      1  id10299\\00004_seg_18.wav  id10299\\00006_seg_6.wav\n",
      "1      1   id10286\\00004_seg_7.wav  id10286\\00007_seg_0.wav\n",
      "2      1  id10282\\00007_seg_24.wav  id10282\\00005_seg_3.wav\n",
      "3      1   id10308\\00003_seg_7.wav  id10308\\00004_seg_4.wav\n",
      "4      1   id10271\\00005_seg_4.wav  id10271\\00004_seg_3.wav\n",
      "\n",
      "Distribution of same/different pairs:\n",
      "label\n",
      "1    16000\n",
      "0    16000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample speaker pairings:\n",
      "id10299 vs id10299: Same = 1\n",
      "id10286 vs id10286: Same = 1\n",
      "id10282 vs id10282: Same = 1\n",
      "id10308 vs id10308: Same = 1\n",
      "id10271 vs id10271: Same = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_16788\\2951298385.py:129: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Create a function to generate trial list CSV for custom dataset with format id10270\\00001_seg_0.wav\n",
    "import random\n",
    "\n",
    "\n",
    "def create_custom_trial_csv(\n",
    "    dataset, output_path, num_positive_per_speaker=10, num_negative_total=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a trial list CSV file from a CustomNoisyEnrollSet dataset\n",
    "\n",
    "    Args:\n",
    "        dataset: CustomNoisyEnrollSet dataset\n",
    "        output_path: Path to save the CSV file\n",
    "        num_positive_per_speaker: Maximum number of positive (same speaker) trials per speaker\n",
    "        num_negative_total: Total number of negative trials (if None, matches positive count)\n",
    "    \"\"\"\n",
    "    # Group samples by speaker ID\n",
    "    speakers = {}\n",
    "    for sample in dataset.samples:\n",
    "        speaker_id = sample[\"speaker_id\"]\n",
    "        audio_path = sample[\"audio_path\"]\n",
    "\n",
    "        if speaker_id not in speakers:\n",
    "            speakers[speaker_id] = []\n",
    "        speakers[speaker_id].append(audio_path)\n",
    "\n",
    "    print(f\"Found {len(speakers)} speakers\")\n",
    "\n",
    "    # Create list for CSV (label, audio1, audio2)\n",
    "    trial_pairs = []\n",
    "\n",
    "    # Create positive pairs (same speaker, label=1)\n",
    "    positive_count = 0\n",
    "    for speaker_id, audio_paths in speakers.items():\n",
    "        # Skip speakers with too few samples\n",
    "        if len(audio_paths) < 2:\n",
    "            continue\n",
    "\n",
    "        # Limit number of positive trials per speaker\n",
    "        speaker_positive_count = 0\n",
    "        max_positive = min(\n",
    "            num_positive_per_speaker, len(audio_paths) * (len(audio_paths) - 1) // 2\n",
    "        )\n",
    "\n",
    "        # Create random positive pairs for this speaker\n",
    "        audio_indices = list(range(len(audio_paths)))\n",
    "        random.shuffle(audio_indices)\n",
    "\n",
    "        for i in range(len(audio_indices)):\n",
    "            for j in range(i + 1, len(audio_indices)):\n",
    "                if speaker_positive_count >= max_positive:\n",
    "                    break\n",
    "\n",
    "                idx1, idx2 = audio_indices[i], audio_indices[j]\n",
    "                trial_pairs.append((1, audio_paths[idx1], audio_paths[idx2]))\n",
    "                speaker_positive_count += 1\n",
    "                positive_count += 1\n",
    "\n",
    "            if speaker_positive_count >= max_positive:\n",
    "                break\n",
    "\n",
    "    # Calculate how many negative trials to create\n",
    "    if num_negative_total is None:\n",
    "        num_negative_total = positive_count\n",
    "\n",
    "    # Create negative pairs (different speakers, label=0)\n",
    "    negative_count = 0\n",
    "    speaker_ids = list(speakers.keys())\n",
    "    max_attempts = num_negative_total * 3  # Allow for duplicates\n",
    "    attempts = 0\n",
    "\n",
    "    negative_pairs_set = set()  # To check for duplicates efficiently\n",
    "\n",
    "    while negative_count < num_negative_total and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "\n",
    "        # Select two random speakers\n",
    "        i = random.randint(0, len(speaker_ids) - 1)\n",
    "        j = random.randint(0, len(speaker_ids) - 1)\n",
    "\n",
    "        if i != j:  # Ensure different speakers\n",
    "            speaker1 = speaker_ids[i]\n",
    "            speaker2 = speaker_ids[j]\n",
    "\n",
    "            # Select random utterances from each speaker\n",
    "            audio1 = random.choice(speakers[speaker1])\n",
    "            audio2 = random.choice(speakers[speaker2])\n",
    "\n",
    "            # Create a unique identifier for this pair (order doesn't matter for uniqueness check)\n",
    "            pair_key = tuple(sorted([audio1, audio2]))\n",
    "\n",
    "            # Check for duplicates\n",
    "            if pair_key not in negative_pairs_set:\n",
    "                negative_pairs_set.add(pair_key)\n",
    "                trial_pairs.append((0, audio1, audio2))\n",
    "                negative_count += 1\n",
    "\n",
    "    # Shuffle the trials for randomness\n",
    "    random.shuffle(trial_pairs)\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(output_path, \"w\") as f:\n",
    "        # Write trials directly without a header (match VoxCeleb format exactly)\n",
    "        for label, audio1, audio2 in trial_pairs:\n",
    "            f.write(f\"{label} {audio1} {audio2}\\n\")\n",
    "\n",
    "    print(\n",
    "        f\"Created trial list with {positive_count} positive and {negative_count} negative pairs\"\n",
    "    )\n",
    "    print(f\"Total trials: {len(trial_pairs)}\")\n",
    "    print(f\"Saved to {output_path}\")\n",
    "\n",
    "    return trial_pairs, positive_count, negative_count\n",
    "\n",
    "\n",
    "# Execute the function to create the CSV\n",
    "output_file = \"label/gaussian_trials.csv\"\n",
    "trials, pos_count, neg_count = create_custom_trial_csv(\n",
    "    dataset=custom_dataset,\n",
    "    output_path=output_file,\n",
    "    num_positive_per_speaker=400,  # Adjust as needed\n",
    "    num_negative_total=None,  # Will match positive count for balance\n",
    ")\n",
    "\n",
    "\n",
    "# Load and verify the created CSV\n",
    "def verify_trial_csv(csv_path):\n",
    "    \"\"\"Verify the created trial list CSV\"\"\"\n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        delim_whitespace=True,\n",
    "        header=None,\n",
    "        names=[\"label\", \"audio1\", \"audio2\"],\n",
    "    )\n",
    "\n",
    "    print(f\"\\nVerifying trial list from {csv_path}\")\n",
    "    print(f\"Shape of dataframe: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nDistribution of same/different pairs:\")\n",
    "    print(df[\"label\"].value_counts())\n",
    "\n",
    "    # Check some of the speaker IDs\n",
    "    print(\"\\nSample speaker pairings:\")\n",
    "    for i in range(min(5, len(df))):\n",
    "        row = df.iloc[i]\n",
    "        speaker1 = (\n",
    "            row[\"audio1\"].split(\"/\")[0]\n",
    "            if \"/\" in row[\"audio1\"]\n",
    "            else row[\"audio1\"].split(\"\\\\\")[0]\n",
    "        )\n",
    "        speaker2 = (\n",
    "            row[\"audio2\"].split(\"/\")[0]\n",
    "            if \"/\" in row[\"audio2\"]\n",
    "            else row[\"audio2\"].split(\"\\\\\")[0]\n",
    "        )\n",
    "        print(f\"{speaker1} vs {speaker2}: Same = {row['label']}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Verify the created CSV\n",
    "trial_df = verify_trial_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5515a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_custom_trial_list(csv_path):\n",
    "    \"\"\"Load a custom trial list from CSV file for evaluation\"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Trial list CSV not found at {csv_path}\")\n",
    "\n",
    "    trials = []\n",
    "    with open(csv_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3:\n",
    "                label = int(parts[0])\n",
    "                audio1 = parts[1]\n",
    "                audio2 = parts[2]\n",
    "                trials.append([audio1, audio2, bool(label)])\n",
    "\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f54b1037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few trials:\n",
      "['id10299\\\\00004_seg_18.wav', 'id10299\\\\00006_seg_6.wav', True]\n",
      "['id10286\\\\00004_seg_7.wav', 'id10286\\\\00007_seg_0.wav', True]\n",
      "['id10282\\\\00007_seg_24.wav', 'id10282\\\\00005_seg_3.wav', True]\n",
      "['id10308\\\\00003_seg_7.wav', 'id10308\\\\00004_seg_4.wav', True]\n",
      "['id10271\\\\00005_seg_4.wav', 'id10271\\\\00004_seg_3.wav', True]\n"
     ]
    }
   ],
   "source": [
    "trail_list = load_custom_trial_list(output_file)\n",
    "# Print the first few trials to verify\n",
    "print(\"First few trials:\")\n",
    "for trial in trail_list[:5]:\n",
    "    print(trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
